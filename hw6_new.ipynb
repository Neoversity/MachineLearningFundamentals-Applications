{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe88256f-2113-4085-9d2b-8d41da7d75fc",
   "metadata": {},
   "source": [
    "## Домашнє завдання до модуля «Алгоритми навчання з вчителем Ч.2»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da23e0c-974b-4517-a7af-2485924214fd",
   "metadata": {},
   "source": [
    "### 1. Здійсніть імпорт необхідних пакетів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7060ba5-ba9b-4568-9e30-bb86d1e72bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee355c-09b2-46cd-bb52-761f44248f87",
   "metadata": {},
   "source": [
    " ### 2. Завантажте набір даних Rain in Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5a2c80-9131-4287-8b82-40ddb9b7a6bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weather_data.csv'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[2], line 1\u001b[0m\n    data = pd.read_csv('weather_data.csv')\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m in \u001b[0;35mread_csv\u001b[0m\n    return _read(filepath_or_buffer, kwds)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m in \u001b[0;35m_read\u001b[0m\n    parser = TextFileReader(filepath_or_buffer, **kwds)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    self._engine = self._make_engine(f, self.engine)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m in \u001b[0;35m_make_engine\u001b[0m\n    self.handles = get_handle(\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[1;36m in \u001b[1;35mget_handle\u001b[1;36m\n\u001b[1;33m    handle = open(\u001b[1;36m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m\u001b[1;31m:\u001b[0m [Errno 2] No such file or directory: 'weather_data.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = pd.read_csv('weather_data.csv')\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e532c8eb-e6a0-4875-b29c-9d51a3f7d5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                 0\n",
      "Location             0\n",
      "MinTemp           1485\n",
      "MaxTemp           1261\n",
      "Rainfall          3261\n",
      "Evaporation      62790\n",
      "Sunshine         69835\n",
      "WindGustDir      10326\n",
      "WindGustSpeed    10263\n",
      "WindDir9am       10566\n",
      "WindDir3pm        4228\n",
      "WindSpeed9am      1767\n",
      "WindSpeed3pm      3062\n",
      "Humidity9am       2654\n",
      "Humidity3pm       4507\n",
      "Pressure9am      15065\n",
      "Pressure3pm      15028\n",
      "Cloud9am         55888\n",
      "Cloud3pm         59358\n",
      "Temp9am           1767\n",
      "Temp3pm           3609\n",
      "RainToday         3261\n",
      "RainTomorrow      3267\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Підрахунок пропущених значень\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Відображення кількості пропущених значень у кожному стовпці\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47883a76-ab01-40a0-94cd-f8e50ea23958",
   "metadata": {},
   "source": [
    "### 3: Видалення ознак з великою кількістю пропущених значень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93a986e6-7dcb-4db9-a82f-75da72745710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість пропущених значень у кожній колонці:\n",
      "Date                 0\n",
      "Location             0\n",
      "MinTemp           1485\n",
      "MaxTemp           1261\n",
      "Rainfall          3261\n",
      "Evaporation      62790\n",
      "Sunshine         69835\n",
      "WindGustDir      10326\n",
      "WindGustSpeed    10263\n",
      "WindDir9am       10566\n",
      "WindDir3pm        4228\n",
      "WindSpeed9am      1767\n",
      "WindSpeed3pm      3062\n",
      "Humidity9am       2654\n",
      "Humidity3pm       4507\n",
      "Pressure9am      15065\n",
      "Pressure3pm      15028\n",
      "Cloud9am         55888\n",
      "Cloud3pm         59358\n",
      "Temp9am           1767\n",
      "Temp3pm           3609\n",
      "RainToday         3261\n",
      "RainTomorrow      3267\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Кількість пропусків у кожній колонці\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Відображення колонок із пропусками\n",
    "print(\"Кількість пропущених значень у кожній колонці:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bc86654-de45-48f0-a517-41be27e4d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонки для видалення (понад 30% пропусків): ['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm']\n"
     ]
    }
   ],
   "source": [
    "# Розрахунок порогу для видалення колонок\n",
    "threshold = len(data) * 0.3\n",
    "\n",
    "# Колонки для видалення\n",
    "columns_to_drop = missing_values[missing_values > threshold].index\n",
    "\n",
    "print(f\"Колонки для видалення (понад 30% пропусків): {list(columns_to_drop)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d6c555f-c1e4-4c16-af77-d97d4fe759a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма даних після видалення колонок: (145460, 19)\n"
     ]
    }
   ],
   "source": [
    "# Видалення колонок із великою кількістю пропусків\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Перевірка оновлених даних\n",
    "print(f\"Форма даних після видалення колонок: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45908ebe-7de2-4b33-af15-b280b4ebf25b",
   "metadata": {},
   "source": [
    "### 3.2. Створіть підмножини набору даних із числовими та категоріальними ознаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4a8ef40-35a0-48f5-8a32-b7428b4b9587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Типи даних у наборі:\n",
      "Date              object\n",
      "Location          object\n",
      "MinTemp          float64\n",
      "MaxTemp          float64\n",
      "Rainfall         float64\n",
      "WindGustDir       object\n",
      "WindGustSpeed    float64\n",
      "WindDir9am        object\n",
      "WindDir3pm        object\n",
      "WindSpeed9am     float64\n",
      "WindSpeed3pm     float64\n",
      "Humidity9am      float64\n",
      "Humidity3pm      float64\n",
      "Pressure9am      float64\n",
      "Pressure3pm      float64\n",
      "Temp9am          float64\n",
      "Temp3pm          float64\n",
      "RainToday         object\n",
      "RainTomorrow      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Перевірка типів даних\n",
    "print(\"Типи даних у наборі:\")\n",
    "print(data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8e1ab52-285d-4bab-b697-595117ee96c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числові ознаки (12):\n",
      "   MinTemp  MaxTemp  Rainfall  ...  Pressure3pm  Temp9am  Temp3pm\n",
      "0     13.4     22.9       0.6  ...       1007.1     16.9     21.8\n",
      "1      7.4     25.1       0.0  ...       1007.8     17.2     24.3\n",
      "2     12.9     25.7       0.0  ...       1008.7     21.0     23.2\n",
      "3      9.2     28.0       0.0  ...       1012.8     18.1     26.5\n",
      "4     17.5     32.3       1.0  ...       1006.0     17.8     29.7\n",
      "\n",
      "[5 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Виділення числових ознак\n",
    "numerical_features = data.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Перевірка підмножини числових ознак\n",
    "print(f\"Числові ознаки ({len(numerical_features.columns)}):\")\n",
    "print(numerical_features.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b883627d-ca29-4af1-aa2f-c7fef1589469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Категоріальні ознаки (7):\n",
      "         Date Location WindGustDir WindDir9am WindDir3pm RainToday RainTomorrow\n",
      "0  2008-12-01   Albury           W          W        WNW        No           No\n",
      "1  2008-12-02   Albury         WNW        NNW        WSW        No           No\n",
      "2  2008-12-03   Albury         WSW          W        WSW        No           No\n",
      "3  2008-12-04   Albury          NE         SE          E        No           No\n",
      "4  2008-12-05   Albury           W        ENE         NW        No           No\n"
     ]
    }
   ],
   "source": [
    "# Виділення категоріальних ознак\n",
    "categorical_features = data.select_dtypes(include=['object'])\n",
    "\n",
    "# Перевірка підмножини категоріальних ознак\n",
    "print(f\"Категоріальні ознаки ({len(categorical_features.columns)}):\")\n",
    "print(categorical_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e28e5beb-d94e-4f6d-a15f-9e0a19bdc5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість числових ознак: 12\n",
      "Кількість категоріальних ознак: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Кількість числових ознак: {numerical_features.shape[1]}\")\n",
    "print(f\"Кількість категоріальних ознак: {categorical_features.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b464aee-837b-4e48-a74a-cfa371a21083",
   "metadata": {},
   "source": [
    "### 3.3. Змініть тип колонки Date на тип datetimeі створіть додаткові колонки Year та Month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c38b4acf-37f0-4250-940d-96e20789fdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка 'Date' успішно перетворена на тип datetime.\n"
     ]
    }
   ],
   "source": [
    "# Зміна типу колонки Date на datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Перевірка змін\n",
    "print(\"Колонка 'Date' успішно перетворена на тип datetime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4c950c5-05da-46ba-bf66-ed68cd3e99af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month\n",
      "0  2008     12\n",
      "1  2008     12\n",
      "2  2008     12\n",
      "3  2008     12\n",
      "4  2008     12\n"
     ]
    }
   ],
   "source": [
    "# Витягуємо рік і місяць\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "\n",
    "# Видаляємо колонку Date\n",
    "data = data.drop(columns=['Date'])\n",
    "\n",
    "# Перевіряємо результат\n",
    "print(data[['Year', 'Month']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7e53c28-dad7-46e4-a627-f6f37f6e8742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Унікальні значення в колонці 'Year': [2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2007]\n",
      "Унікальні значення в колонці 'Month': [12  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "# Унікальні значення в колонках Year і Month\n",
    "print(\"Унікальні значення в колонці 'Year':\", data['Year'].unique())\n",
    "print(\"Унікальні значення в колонці 'Month':\", data['Month'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c48b031-7caa-4684-a42d-3f019f9f7a0d",
   "metadata": {},
   "source": [
    "###  3.4. Переміcтить створену нову колонку Year з підмножини набору із категоріальними ознаками до підмножини із числовими ознаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "409df33c-d564-4000-be03-9f72c71de6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оновлені числові ознаки:\n",
      "   MinTemp  MaxTemp  Rainfall  ...  Temp9am  Temp3pm  Year\n",
      "0     13.4     22.9       0.6  ...     16.9     21.8  2008\n",
      "1      7.4     25.1       0.0  ...     17.2     24.3  2008\n",
      "2     12.9     25.7       0.0  ...     21.0     23.2  2008\n",
      "3      9.2     28.0       0.0  ...     18.1     26.5  2008\n",
      "4     17.5     32.3       1.0  ...     17.8     29.7  2008\n",
      "\n",
      "[5 rows x 13 columns]\n",
      "Оновлені категоріальні ознаки:\n",
      "         Date Location WindGustDir WindDir9am WindDir3pm RainToday RainTomorrow\n",
      "0  2008-12-01   Albury           W          W        WNW        No           No\n",
      "1  2008-12-02   Albury         WNW        NNW        WSW        No           No\n",
      "2  2008-12-03   Albury         WSW          W        WSW        No           No\n",
      "3  2008-12-04   Albury          NE         SE          E        No           No\n",
      "4  2008-12-05   Albury           W        ENE         NW        No           No\n"
     ]
    }
   ],
   "source": [
    "# Додавання Year до числових ознак\n",
    "numerical_features['Year'] = data['Year']\n",
    "\n",
    "# Видалення Year із категоріальних ознак, якщо випадково потрапила туди\n",
    "if 'Year' in categorical_features.columns:\n",
    "    categorical_features = categorical_features.drop(columns=['Year'])\n",
    "\n",
    "# Перевірка підмножин\n",
    "print(\"Оновлені числові ознаки:\")\n",
    "print(numerical_features.head())\n",
    "\n",
    "print(\"Оновлені категоріальні ознаки:\")\n",
    "print(categorical_features.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "712ed7e3-ec46-4118-a22b-8af9656f69d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип колонки 'Year': int32\n",
      "Тип колонки 'Month': category\n"
     ]
    }
   ],
   "source": [
    "# Перевірка типу Year\n",
    "print(f\"Тип колонки 'Year': {data['Year'].dtype}\")\n",
    "\n",
    "# Переведення Month у категоріальний тип, якщо це ще не зроблено\n",
    "data['Month'] = data['Month'].astype('category')\n",
    "print(f\"Тип колонки 'Month': {data['Month'].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cfc046f0-5cec-48a8-827a-19163f121f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість числових ознак: 13\n",
      "Кількість категоріальних ознак: 7\n"
     ]
    }
   ],
   "source": [
    "# Відображення кількості колонок у підмножинах\n",
    "print(f\"Кількість числових ознак: {numerical_features.shape[1]}\")\n",
    "print(f\"Кількість категоріальних ознак: {categorical_features.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5075a2a7-2323-4fc5-9375-ad86a2d7b3f5",
   "metadata": {},
   "source": [
    "### 3.5. Розбийте підмножини на тренувальну і тестову вибірки за такою логікою: до тестової вибірки віднесіть всі об'єкти із набору даних із останнім (максимальним) роком спостережень, а для навчання моделі залиште всі інші об'єкти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcf9981e-a9b9-4b03-af7f-dc3a70d66fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальний рік у даних: 2017\n"
     ]
    }
   ],
   "source": [
    "# Визначення максимального року\n",
    "max_year = data['Year'].max()\n",
    "print(f\"Максимальний рік у даних: {max_year}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fd80f98f-8ef2-4a4d-9bc1-ca5702f9ec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розмір тренувальної вибірки: (136837, 20)\n",
      "Розмір тестової вибірки: (8623, 20)\n"
     ]
    }
   ],
   "source": [
    "# Розділення даних\n",
    "train_data = data[data['Year'] < max_year]\n",
    "test_data = data[data['Year'] == max_year]\n",
    "\n",
    "print(f\"Розмір тренувальної вибірки: {train_data.shape}\")\n",
    "print(f\"Розмір тестової вибірки: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a23baa7a-8be2-4bd7-9e62-06b9d3b868ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = train_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = train_data.select_dtypes(include=['object', 'category']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1b5f0d66-50c9-4c14-a925-f22186ca028a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Унікальні роки у тренувальній вибірці: [2008 2009 2010 2011 2012 2013 2014 2015 2016 2007]\n",
      "Унікальні роки у тестовій вибірці: [2017]\n"
     ]
    }
   ],
   "source": [
    "# Перевірка унікальних років у кожній вибірці\n",
    "print(f\"Унікальні роки у тренувальній вибірці: {train_data['Year'].unique()}\")\n",
    "print(f\"Унікальні роки у тестовій вибірці: {test_data['Year'].unique()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9acf9f-2541-42f1-a112-4dd3435a97ea",
   "metadata": {},
   "source": [
    "### 4. Відновіть пропущені дані за допомогою об'єкта SimpleImputer з пакету sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6109d549-ce07-4729-a1a5-ef1cf66a41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "732cf083-d987-4071-9e44-8555659fce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски у числових даних:\n",
      "0\n",
      "Пропуски у категоріальних даних:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Перевірка пропусків у числових ознаках\n",
    "print(f\"Пропуски у числових даних:\\n{numerical_features.isnull().sum()}\")\n",
    "\n",
    "# Перевірка пропусків у категоріальних ознаках\n",
    "print(f\"Пропуски у категоріальних даних:\\n{categorical_features.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d9685a28-5d24-4c01-8eab-0221c23f6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Імп'ютер та масштабувальник для числових даних\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Заповнення пропущених значень та масштабування для тренувальних даних\n",
    "train_data.loc[:, numerical_features] = numerical_imputer.fit_transform(train_data[numerical_features])\n",
    "train_data.loc[:, numerical_features] = scaler.fit_transform(train_data[numerical_features])\n",
    "\n",
    "# Заповнення пропущених значень та масштабування для тестових даних\n",
    "test_data.loc[:, numerical_features] = numerical_imputer.transform(test_data[numerical_features])\n",
    "test_data.loc[:, numerical_features] = scaler.transform(test_data[numerical_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "50afca87-4157-43c9-a6ed-b4196579a20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чи є пропуски у категоріальних даних після заповнення? 0\n"
     ]
    }
   ],
   "source": [
    "# Ініціалізація SimpleImputer\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "\n",
    "# Заповнення пропущених значень у тренувальних даних\n",
    "train_data.loc[:, categorical_features] = categorical_imputer.fit_transform(train_data[categorical_features])\n",
    "\n",
    "# Заповнення пропущених значень у тестових даних\n",
    "test_data.loc[:, categorical_features] = categorical_imputer.transform(test_data[categorical_features])\n",
    "\n",
    "# Перевірка, чи є пропуски\n",
    "print(f\"Чи є пропуски у категоріальних даних після заповнення? {categorical_features_imputed.isnull().sum().sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "84915bc4-328f-4c8d-8d90-242a0adb6281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оновлена кількість числових ознак: 13\n",
      "Оновлена кількість категоріальних ознак: 7\n"
     ]
    }
   ],
   "source": [
    "# Оновлення числових та категоріальних підмножин\n",
    "numerical_features = numerical_features_imputed\n",
    "categorical_features = categorical_features_imputed\n",
    "\n",
    "# Перевірка форми\n",
    "print(f\"Оновлена кількість числових ознак: {numerical_features.shape[1]}\")\n",
    "print(f\"Оновлена кількість категоріальних ознак: {categorical_features.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "107a5110-cf20-4966-80b9-40d7a9e697c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чи залишилися пропуски у наборі даних? 0\n"
     ]
    }
   ],
   "source": [
    "# Об'єднання очищених даних\n",
    "data_cleaned = pd.concat([numerical_features, categorical_features], axis=1)\n",
    "\n",
    "# Перевірка, чи є пропуски у фінальному наборі\n",
    "print(f\"Чи залишилися пропуски у наборі даних? {data_cleaned.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede9644-8915-44de-8c02-5b06c7e93221",
   "metadata": {},
   "source": [
    "### 5. Нормалізуйте числові ознаки за допомогою об'єкта StandardScaler з пакету sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f085ab3-41de-424b-9dd3-97ccb90c8feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1ca9614b-0924-4b6e-a21c-0a8f92142877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "18fabb73-8a0a-47dd-9542-085b0dd86aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обробка числових даних завершена.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Оновлення імп'ютера\n",
    "numerical_imputer = SimpleImputer(strategy='mean').set_output(transform='pandas')\n",
    "\n",
    "# Заповнення пропущених значень\n",
    "train_data.loc[:, numerical_features] = numerical_imputer.fit_transform(train_data[numerical_features])\n",
    "test_data.loc[:, numerical_features] = numerical_imputer.transform(test_data[numerical_features])\n",
    "\n",
    "# Масштабування числових даних\n",
    "scaler = StandardScaler()\n",
    "train_data.loc[:, numerical_features] = scaler.fit_transform(train_data[numerical_features])\n",
    "test_data.loc[:, numerical_features] = scaler.transform(test_data[numerical_features])\n",
    "\n",
    "print(\"Обробка числових даних завершена.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6fda2945-1784-4252-97b0-b5d93d81ca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp          0\n",
      "MaxTemp          0\n",
      "Rainfall         0\n",
      "WindGustSpeed    0\n",
      "WindSpeed9am     0\n",
      "WindSpeed3pm     0\n",
      "Humidity9am      0\n",
      "Humidity3pm      0\n",
      "Pressure9am      0\n",
      "Pressure3pm      0\n",
      "Temp9am          0\n",
      "Temp3pm          0\n",
      "dtype: int64\n",
      "MinTemp          0\n",
      "MaxTemp          0\n",
      "Rainfall         0\n",
      "WindGustSpeed    0\n",
      "WindSpeed9am     0\n",
      "WindSpeed3pm     0\n",
      "Humidity9am      0\n",
      "Humidity3pm      0\n",
      "Pressure9am      0\n",
      "Pressure3pm      0\n",
      "Temp9am          0\n",
      "Temp3pm          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data[numerical_features].isnull().sum())\n",
    "print(test_data[numerical_features].isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042470d-4726-43c2-8f77-511b7d844f7d",
   "metadata": {},
   "source": [
    "### 6. Виконайте кодування категоріальних ознак за допомогою об’єкта OneHotEncoder з пакету sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2425e334-e8c8-4b55-a646-d2c905b503c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4355cacc-05a1-44ab-94d3-42a2eb6576fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c4fcbc3a-5f87-488b-b14f-056e87d6209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перші кілька рядків закодованих категоріальних ознак:\n",
      "   Date_2007-11-02  Date_2007-11-03  ...  RainToday_Yes  RainTomorrow_Yes\n",
      "0              0.0              0.0  ...            0.0               0.0\n",
      "1              0.0              0.0  ...            0.0               0.0\n",
      "2              0.0              0.0  ...            0.0               0.0\n",
      "3              0.0              0.0  ...            0.0               0.0\n",
      "4              0.0              0.0  ...            0.0               0.0\n",
      "\n",
      "[5 rows x 3530 columns]\n"
     ]
    }
   ],
   "source": [
    "# Кодування категоріальних ознак\n",
    "categorical_features_encoded = pd.DataFrame(\n",
    "    encoder.fit_transform(categorical_features),\n",
    "    columns=encoder.get_feature_names_out(categorical_features.columns)\n",
    ")\n",
    "\n",
    "# Перевірка результату\n",
    "print(\"Перші кілька рядків закодованих категоріальних ознак:\")\n",
    "print(categorical_features_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d1e6817e-aa82-47b2-ba69-8f69ee18b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість колонок після кодування категоріальних ознак: 3530\n"
     ]
    }
   ],
   "source": [
    "# Оновлення категоріальних ознак\n",
    "categorical_features = categorical_features_encoded\n",
    "\n",
    "# Перевірка форми категоріальних ознак\n",
    "print(f\"Кількість колонок після кодування категоріальних ознак: {categorical_features.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d7f69949-5312-4df9-b991-34bc09ef6139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Типи даних у закодованих категоріальних ознаках:\n",
      "float64    3530\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Перевірка типу даних після кодування\n",
    "print(\"Типи даних у закодованих категоріальних ознаках:\")\n",
    "print(categorical_features.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1e8a6-2f91-43e4-b98d-625a09bdf570",
   "metadata": {},
   "source": [
    "### 7. Об'єднайте підмножини з числовими і категоріальними ознаками (після кодування) для побудови моделі за допомогою об’єкта LogisticRegression з пакету sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "41c002dd-cd1e-4b3c-b64b-fad83db58a5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[147], line 16\u001b[0m\n    X_train_num = imputer_num.fit_transform(X_train[numerical_columns])\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m in \u001b[0;35mwrapped\u001b[0m\n    data_to_wrap = f(self, X, *args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m in \u001b[0;35mfit_transform\u001b[0m\n    return self.fit(X, **fit_params).transform(X)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m in \u001b[0;35mwrapper\u001b[0m\n    return fit_method(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\impute\\_base.py:421\u001b[0m in \u001b[0;35mfit\u001b[0m\n    X = self._validate_input(X, in_fit=True)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\impute\\_base.py:350\u001b[0m in \u001b[0;35m_validate_input\u001b[0m\n    raise ve\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\impute\\_base.py:332\u001b[0m in \u001b[0;35m_validate_input\u001b[0m\n    X = self._validate_data(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m in \u001b[0;35m_validate_data\u001b[0m\n    out = check_array(X, input_name=\"X\", **check_params)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\utils\\validation.py:887\u001b[1;36m in \u001b[1;35mcheck_array\u001b[1;36m\n\u001b[1;33m    dtype_orig = np.result_type(*dtypes_orig)\u001b[1;36m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m at least one array or dtype is required\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 1. Підготовка числових і категоріальних ознак\n",
    "numerical_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Заповнення пропусків\n",
    "imputer_num = SimpleImputer(strategy='mean').set_output(transform='pandas')\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent').set_output(transform='pandas')\n",
    "\n",
    "X_train_num = imputer_num.fit_transform(X_train[numerical_columns])\n",
    "X_test_num = imputer_num.transform(X_test[numerical_columns])\n",
    "\n",
    "X_train_cat = imputer_cat.fit_transform(X_train[categorical_columns])\n",
    "X_test_cat = imputer_cat.transform(X_test[categorical_columns])\n",
    "\n",
    "# Масштабування числових ознак\n",
    "scaler = StandardScaler().set_output(transform='pandas')\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "\n",
    "# Кодування категоріальних ознак\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_train_cat = pd.DataFrame(encoder.fit_transform(X_train_cat), columns=encoder.get_feature_names_out(categorical_columns))\n",
    "X_test_cat = pd.DataFrame(encoder.transform(X_test_cat), columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Об'єднання числових і категоріальних ознак\n",
    "X_train_final = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_test_final = pd.concat([X_test_num, X_test_cat], axis=1)\n",
    "\n",
    "# Перевірка форми об'єднаного датасету\n",
    "print(f\"Розмірність тренувального набору: {X_train_final.shape}\")\n",
    "print(f\"Розмірність тестового набору: {X_test_final.shape}\")\n",
    "\n",
    "# 2. Побудова логістичної регресії з різними solver\n",
    "def train_and_evaluate(solver):\n",
    "    model = LogisticRegression(solver=solver, max_iter=500, random_state=42)\n",
    "    model.fit(X_train_final, y_train)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return solver, accuracy\n",
    "\n",
    "# Solver-и для перевірки\n",
    "solvers = ['lbfgs', 'liblinear', 'saga', 'newton-cg']\n",
    "\n",
    "# Виконання в циклі\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate)(solver) for solver in solvers\n",
    ")\n",
    "\n",
    "# Перетворення результатів у словник\n",
    "results_dict = dict(results)\n",
    "\n",
    "# 3. Відображення результатів\n",
    "print(\"Точність моделі для різних solver:\")\n",
    "for solver, acc in results_dict.items():\n",
    "    print(f\"{solver}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "04aa036c-f95a-41d6-81bf-f70420a26352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розмірність фінального датасету ознак: (136837, 32)\n"
     ]
    }
   ],
   "source": [
    "# Перетворення numerical_features та categorical_features\n",
    "numerical_features = train_data[numerical_features]\n",
    "categorical_features = train_data[categorical_features]\n",
    "\n",
    "# Об'єднання\n",
    "X = pd.concat([numerical_features, categorical_features], axis=1)\n",
    "\n",
    "# Перевірка\n",
    "print(f\"Розмірність фінального датасету ознак: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7f682bd0-bcdc-4547-b010-b6b136fb292c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розмірність фінального датасету ознак: (145460, 19)\n",
      "Розмірність цільової змінної: (145460,)\n"
     ]
    }
   ],
   "source": [
    "# Видалення цільової змінної з основного набору даних\n",
    "X = data_cleaned.drop(columns=['RainTomorrow'])\n",
    "\n",
    "# Перевірка розмірностей\n",
    "print(f\"Розмірність фінального датасету ознак: {X.shape}\")\n",
    "print(f\"Розмірність цільової змінної: {y.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cd49ff88-049d-4a27-927c-e25f4a870305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розмір тренувальної вибірки: (116368, 19), тестової: (29092, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Розділення на тренувальну і тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Перевірка розмірів вибірок\n",
    "print(f\"Розмір тренувальної вибірки: {X_train.shape}, тестової: {X_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "11a2d4c1-359a-4139-955d-30ff294425cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обробка числових даних завершена.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Вибір числових колонок\n",
    "numerical_features = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Налаштування імп'ютера\n",
    "numerical_imputer = SimpleImputer(strategy='mean').set_output(transform='pandas')\n",
    "\n",
    "# Заповнення пропущених значень\n",
    "train_data.loc[:, numerical_features] = numerical_imputer.fit_transform(train_data[numerical_features])\n",
    "test_data.loc[:, numerical_features] = numerical_imputer.transform(test_data[numerical_features])\n",
    "\n",
    "# Масштабування даних\n",
    "scaler = StandardScaler()\n",
    "train_data.loc[:, numerical_features] = scaler.fit_transform(train_data[numerical_features])\n",
    "test_data.loc[:, numerical_features] = scaler.transform(test_data[numerical_features])\n",
    "\n",
    "print(\"Обробка числових даних завершена.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0b296321-4c8a-4761-8635-0e23f4505df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29092 entries, 100721 to 80574\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MinTemp        29092 non-null  float64\n",
      " 1   MaxTemp        29092 non-null  float64\n",
      " 2   Rainfall       29092 non-null  float64\n",
      " 3   WindGustSpeed  29092 non-null  float64\n",
      " 4   WindSpeed9am   29092 non-null  float64\n",
      " 5   WindSpeed3pm   29092 non-null  float64\n",
      " 6   Humidity9am    29092 non-null  float64\n",
      " 7   Humidity3pm    29092 non-null  float64\n",
      " 8   Pressure9am    29092 non-null  float64\n",
      " 9   Pressure3pm    29092 non-null  float64\n",
      " 10  Temp9am        29092 non-null  float64\n",
      " 11  Temp3pm        29092 non-null  float64\n",
      " 12  Year           29092 non-null  float64\n",
      " 13  Location       29092 non-null  int64  \n",
      " 14  WindGustDir    29092 non-null  int64  \n",
      " 15  WindDir9am     29092 non-null  int64  \n",
      " 16  WindDir3pm     29092 non-null  int64  \n",
      " 17  RainToday      29092 non-null  int64  \n",
      "dtypes: float64(13), int64(5)\n",
      "memory usage: 4.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c76bf994-f62b-4bfd-8db9-266f49a59bb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[146], line 18\u001b[0m\n    X_train_imputed = imputer.fit_transform(X_train)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m in \u001b[0;35mwrapped\u001b[0m\n    data_to_wrap = f(self, X, *args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m in \u001b[0;35mfit_transform\u001b[0m\n    return self.fit(X, **fit_params).transform(X)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m in \u001b[0;35mwrapper\u001b[0m\n    return fit_method(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\impute\\_base.py:421\u001b[0m in \u001b[0;35mfit\u001b[0m\n    X = self._validate_input(X, in_fit=True)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\impute\\_base.py:350\u001b[0m in \u001b[0;35m_validate_input\u001b[0m\n    raise ve\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\impute\\_base.py:332\u001b[0m in \u001b[0;35m_validate_input\u001b[0m\n    X = self._validate_data(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m in \u001b[0;35m_validate_data\u001b[0m\n    out = check_array(X, input_name=\"X\", **check_params)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\mlf\\Lib\\site-packages\\sklearn\\utils\\validation.py:887\u001b[1;36m in \u001b[1;35mcheck_array\u001b[1;36m\n\u001b[1;33m    dtype_orig = np.result_type(*dtypes_orig)\u001b[1;36m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m at least one array or dtype is required\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Визначення числових колонок\n",
    "numerical_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# 2. Перевірка спільних колонок між тренувальними і тестовими наборами\n",
    "common_columns = numerical_columns.intersection(X_test.columns)\n",
    "\n",
    "# 3. Приведення тренувальних і тестових наборів до однакових колонок\n",
    "X_train = X_train[common_columns]\n",
    "X_test = X_test[common_columns]\n",
    "\n",
    "# 4. Заповнення пропусків\n",
    "imputer = SimpleImputer(strategy='mean').set_output(transform='pandas')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# 5. Масштабування числових даних\n",
    "scaler = StandardScaler().set_output(transform='pandas')\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Перевірка форм наборів\n",
    "print(f\"Розмірність X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"Розмірність X_test_scaled: {X_test_scaled.shape}\")\n",
    "\n",
    "# 6. Навчання моделі\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=500, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Передбачення\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 8. Оцінка точності\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Точність моделі: {accuracy:.4f}\")\n",
    "\n",
    "# 9. Звіт класифікації\n",
    "print(\"Звіт класифікації:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7c45d-0d96-4ab1-b015-279c86d84a38",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dd4ff29e-b1e0-4cf3-99ed-6a414f5c4dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[140], line 8\u001b[1;36m\n\u001b[1;33m    X_test = X_test.sample(frac=0.1, random_state=42)\u001b[1;36m\n",
      "\u001b[1;31mAttributeError\u001b[0m\u001b[1;31m:\u001b[0m 'numpy.ndarray' object has no attribute 'sample'\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Зменшення розміру даних для тестування\n",
    "X_train = X_train.sample(frac=0.1, random_state=42)\n",
    "y_train = y_train[X_train.index]\n",
    "X_test = X_test.sample(frac=0.1, random_state=42)\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "# Функція для тренування моделі\n",
    "def train_and_evaluate(solver, X_train, y_train, X_test, y_test):\n",
    "    model = LogisticRegression(solver=solver, max_iter=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return solver, accuracy\n",
    "\n",
    "# Solver-и для перевірки\n",
    "solvers = ['lbfgs', 'liblinear']  # Лише найефективніші\n",
    "\n",
    "# Паралельне виконання\n",
    "results = Parallel(n_jobs=2)(delayed(train_and_evaluate)(solver, X_train, y_train, X_test, y_test) for solver in solvers)\n",
    "\n",
    "# Перетворення результатів у словник\n",
    "results_dict = dict(results)\n",
    "\n",
    "# Виведення результатів\n",
    "print(\"Точність моделі для різних solver:\")\n",
    "for solver, acc in results_dict.items():\n",
    "    print(f\"{solver}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "64ee4f48-f32d-45d5-aba6-13cc09de9e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість спільних рядків: 0\n",
      "Унікальний ідентифікатор відсутній, перевірка лише на рівень рядків.\n"
     ]
    }
   ],
   "source": [
    "# Перевірка на збіг рядків між train_data і test_data\n",
    "common_rows = pd.merge(train_data, test_data, how='inner')\n",
    "print(f\"Кількість спільних рядків: {len(common_rows)}\")\n",
    "\n",
    "# Перевірка на збіг унікальних ідентифікаторів (якщо є унікальний стовпець)\n",
    "if 'ID' in train_data.columns and 'ID' in test_data.columns:\n",
    "    common_ids = set(train_data['ID']).intersection(set(test_data['ID']))\n",
    "    print(f\"Кількість спільних ідентифікаторів: {len(common_ids)}\")\n",
    "else:\n",
    "    print(\"Унікальний ідентифікатор відсутній, перевірка лише на рівень рядків.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c4c73-3803-42fb-87a7-5423be6ee7de",
   "metadata": {},
   "source": [
    "### Висновки:\n",
    "1. Різке підвищення точності: Нова модель досягла ідеальної точності (1.00) для обох класів No та Yes, що свідчить про те, що модель здатна повністю розпізнавати тестові дані.\n",
    "2. Баланс між класами: На відміну від базової моделі, нова модель показала ідентичні значення метрик (precision, recall, f1-score) для всіх класів.\n",
    "3. Можливий Overfitting: Такі високі метрики можуть бути ознакою надмірного навчання, особливо якщо тестові дані мають структуру, схожу на тренувальні.\n",
    "\n",
    "### Рекомендації:\n",
    "1. Перевірка узагальнювальної здатності моделі:\n",
    "Провести тестування на зовсім новому наборі даних (наприклад, із іншого джерела), щоб переконатися у відсутності overfitting.\n",
    "2. Аналіз класів: Нова модель значно краще справляється із класом меншості (Yes), ніж базова модель. Це може свідчити про те, що використання додаткових ознак, таких як Year та Month, позитивно вплинуло на результати.\n",
    "3. Додаткові метрики: Для задачі з незбалансованими класами перевірте balanced accuracy або f1-score для більш точного аналізу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5524e-2fa3-4479-88fd-3293d150aa27",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           No       1.00      1.00      1.00     22672\n",
    "          Yes       1.00      1.00      1.00      6420\n",
    "\n",
    "    accuracy                            1.00     29092  \n",
    "    macro avg       1.00      1.00      1.00     29092\n",
    "    weighted avg    1.00      1.00      1.00     29092\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100846b-74d7-42dc-a490-42334f8fe7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
